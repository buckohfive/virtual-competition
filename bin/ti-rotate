#!/usr/bin/python

import sys
import os
import json
import argparse
import time
import signal
import hashlib
import subprocess
import random
import logging
import fcntl
import binascii
import shutil
from collections import defaultdict

negotiation_failures = ["invalid type", "bits", "protocol"]

def try_makedirs(d):
    if os.path.isdir(d):
         return
    os.makedirs(d)

def hash_file(filename):
    sha = hashlib.sha256()

    with open(filename, "r") as infile:
        while True:
            block = infile.read(65536)
            if not block:
                break
            sha.update(block)
    return sha.hexdigest()

def make_uri(path):
    return path.split('webroot')[-1]

def set_add(_list, _item):
    if _item not in _list:
        _list.append(_item)

# Removed: mutate_ids

def mutate_rcb(path, team, fixed_replacement=None):
    logging.debug("mutating rcb %s for team %d" % (path, team))

    mutate_time = int(time.time())
    tmpname = binascii.hexlify(os.urandom(7))

    parts = path.split(os.sep)
    parts[-3] = str(team)
    oldname = parts[-1]
    parts[-1] = tmpname
    new_path = os.sep + os.path.join(*parts)
    result = None

    if fixed_replacement:
        # ADDED: Use the provided CB
        logging.debug("Replacing with pre-compiled %s. Previous rcb %s, team %d" % (fixed_replacement, path, team))
        shutil.copyfile(fixed_replacement, new_path)
    else:
        # As in DARPA's ti-rotate, randomize Merino!
        shutil.copyfile(path, new_path)
        with open(new_path, 'r+') as f:
            f.seek(9)
            f.write(os.urandom(7))

    new_hash = hash_file(new_path)

    name_parts = oldname.split('_')[:-2]
    name_parts.append(new_hash)
    name_parts.append("%d" % mutate_time)
    parts[-1] = '_'.join(name_parts)
    final_path = os.sep + os.path.join(*parts)
    os.rename(new_path, final_path)

    return (final_path, new_hash)


def is_locked(path):
    result = False

    with open(path, 'r') as f:
        try:
            fcntl.flock(f, fcntl.LOCK_EX | fcntl.LOCK_NB)
            fcntl.flock(f, fcntl.LOCK_UN)
        except IOError:
            result = True

    return result

class Rotator(object):
    # Binary status
    NEW = 'new'
    NEW2 = 'new2'
    DOWN = 'down'
    FIELDED = 'fielded'
    SUBMITTED_WHEN_NEW = 'submitted_when_new'

    def __init__(self, seconds, webroot, cbdir, team, polls, cs_limit, cs_rounds_duration):
        self.round_length = seconds

        #where files are served from, where we need to save our json
        self.web_root = webroot
        self.initial_cbdir = cbdir
        self.source_cbdir = os.path.join(cbdir, '../cgc-challenges-unfielded')
        self.dest_cbdir = os.path.join(cbdir, '../cgc-challenges-spent')
        if not os.path.exists(self.source_cbdir):
            os.mkdir(self.source_cbdir)
        if not os.path.exists(self.dest_cbdir):
            os.mkdir(self.dest_cbdir)

        scores_path = os.path.join(cbdir, '../scores.json')
        if os.path.exists(scores_path):
            self.cached_scores = json.load(open(scores_path))
        else:
            self.cached_scores = {}

        self.polls = polls

        self.cs_limit = cs_limit
        self.cs_rounds_duration = cs_rounds_duration

        self.round_num = 0

        self.my_team = team
        self.csets = {}
        self.round_time = 0
        self.installed_povs = {}

        self.precompiled_cbs = defaultdict(list)

        self.teams = [i for i in range(1, 8)]
        self.installed_filters = {team:{} for team in self.teams}
        self.scores = {i:0 for i in self.teams}
        self.signals = [signal.SIGILL, signal.SIGSEGV, signal.SIGBUS]

        self.my_filters = self.installed_filters[self.my_team]

        try_makedirs(self.web_root)

        self.write_round_num()

    def write_round_num(self):
        with open(os.path.join(self.web_root, "cgc-round"), "w") as round_file:
            round_file.write("%d" % self.round_num)

    def rotate_cbs(self):
        (_, current_cs_list, _) = os.walk(self.initial_cbdir).next()
        (_, source_cs_list, _) = os.walk(self.source_cbdir).next()
        if len(source_cs_list) == 0:
            # there are no challenge sets to swap in. abort
            return

        if len(current_cs_list) != 0:
            # swap out the current challenge sets
            for cs in current_cs_list:
                shutil.move(os.path.join(self.initial_cbdir, cs), os.path.join(self.dest_cbdir, cs))

            try:
                (rcb_path, _, old_rcb_list) = os.walk(os.path.join(self.web_root, 'rcb_fielded')).next()
                for rcb in old_rcb_list:
                    os.remove(os.path.join(rcb_path, rcb))
            except StopIteration:
                pass

            try:
                (rcb_path, _, old_rcb_list) = os.walk(os.path.join(self.web_root, 'rcb')).next()
                for rcb in old_rcb_list:
                    os.remove(os.path.join(rcb_path, rcb))
            except StopIteration:
                pass

        # swap in some new challenge sets
        in_count = random.randrange(3, 8)
        if in_count >= len(source_cs_list) - 2:
            in_count = len(source_cs_list)
        random.shuffle(source_cs_list)
        for cs in source_cs_list[:in_count]:
            shutil.move(os.path.join(self.source_cbdir, cs), os.path.join(self.initial_cbdir, cs))

    def install_cbs(self):
        cbdir = self.initial_cbdir
        #The binaries in this directory form the valid set of cbs for
        #the purposes of the CFE simulator
        (dirpath, dirnames, _) = os.walk(cbdir).next()
        binaries = random.sample(dirnames, min(len(dirnames), self.cs_limit))
        logging.debug("NEW CHALLENGE SETS OUT! %s", binaries)
        #TODO: now copy these into the round 0 evaluation directory

        install_time = int(time.time())

        # reset cb variables
        self.csets = {}
        self.installed_cbs = {team:{} for team in self.teams}
        self.my_cbs = self.installed_cbs[self.my_team]
        self.my_cbs_status = {} # CSID: new, fielded, down, fielded

        #need to setup a dict that represents csids and number of associated cbs
        for csid in binaries:
            (csidpath, _, cbnames) = os.walk(os.path.join(cbdir, csid, "bin")).next()
            for cb in cbnames:
                self.precompiled_cbs[csid].append(os.path.join(cbdir, csid, "bin", cb))
                if '_patched' in cb:
                    continue
                if csid in self.csets:
                    self.csets[csid] += 1
                else:
                    self.csets[csid] = 1
                self.my_cbs_status[csid] = self.NEW

                cb_loc = os.path.join(csidpath, cb)
                cbhash = hash_file(cb_loc)

                #install initial CBS to all teams
                for team in self.teams:
                    #make sure download directories are created
                    cb_install_dir = os.path.join(self.web_root, "dl", str(team), "cb")
                    try_makedirs(cb_install_dir)
                    install_path = os.path.join(cb_install_dir, "%s_%s_%d" % (cb, cbhash, install_time))
                    shutil.copyfile(cb_loc, install_path)
                    self.installed_cbs[team][cb] = {"timestamp":0, "csid":csid, "path":install_path, "hash":cbhash}

    def install_filters(self):
        #install initial filters to all teams

        base_ids_rule = '#empty\n'
        install_time = int(time.time())
        filter_hash = hashlib.sha256(base_ids_rule).hexdigest()

        for team in self.teams:
            ids_install_dir = os.path.join(self.web_root, "dl", str(team), "ids")
            try_makedirs(ids_install_dir)

            for csid in self.csets:
                install_path = os.path.join(ids_install_dir, "%s_%s_%d.ids" % (csid, filter_hash, install_time))

                with open(install_path, "wb") as ids_filter:
                    ids_filter.write(base_ids_rule)

                self.installed_filters[team][csid] = {"timestamp":install_time, "path":install_path, "hash":filter_hash}

    def issue_povs(self):
        if self.round_num == 0:
            return

        for team in self.teams:
            if team != self.my_team:
                chance = random.randrange(1000)
                if chance < 50:
                    #give this team a new pov
                    #perhaps scp it to pov thrower to throw against self.my_team
                    #choose a pov from self.installed_povs to donate to this team
                    pass

    def issue_ids(self):
        # DISABLED
        return

    def issue_rcbs(self):
        if self.round_num == 0:
            return

        for team in self.teams:
            if team != self.my_team:
                chance = random.randrange(1000)
                if chance < 20:
                    # ADDED: this team will (re)deploy an official, possibly patched, version
                    rand_cbid = random.choice(self.installed_cbs[team].keys())
                    rcb = self.installed_cbs[team][rand_cbid]
                    original = random.choice(self.precompiled_cbs[rcb['csid']])
                    new_path, new_hash = mutate_rcb(rcb['path'], team, fixed_replacement=original)
                    new_rcb = {}
                    new_rcb['timestamp'] = int(time.time())
                    new_rcb['hash'] = new_hash
                    new_rcb['path'] = new_path
                    new_rcb['csid'] = rcb['csid']
                    self.installed_cbs[team][rand_cbid] = new_rcb
                if chance < 50:
                    #give this team a new (randomly-mutated copy) rcb
                    while True:
                        donor = random.randint(1, 7)
                        if donor != team and len(self.installed_filters[donor]) > 0:
                            rcbs = self.installed_cbs[donor]
                            cbids = rcbs.keys()
                            rand_cbid = random.choice(cbids)
                            rcb = rcbs[rand_cbid]
                            new_path, new_hash = mutate_rcb(rcb['path'], team)
                            new_rcb = {}
                            new_rcb['timestamp'] = int(time.time())
                            new_rcb['hash'] = new_hash
                            new_rcb['path'] = new_path
                            new_rcb['csid'] = rcb['csid']
                            self.installed_cbs[team][rand_cbid] = new_rcb
                            break

    def distribute_pov(self):
        install_path = os.path.join(self.web_root, "dl", str(self.my_team), "pov")
        try_makedirs(install_path)

        pov_dir = os.path.join(self.web_root, 'pov')
        try:
            (dirpath, _, new_povs) = os.walk(pov_dir).next()
        except StopIteration:
            logging.error("No POVs to distribute")
            new_povs = []

        #TODO: update map of currently installed povs
        #csid -> povname (with hash suffix)
        temp_povs = {} #handle multiple submissions against same csid
        for pov in new_povs:
            pov_file = os.path.join(dirpath, pov)
            if is_locked(pov_file):
                #still being written by web server
                continue

            parts = pov.split('_')
            ts = int(parts[-1][:-4]) # timestamp
            throws = int(parts[-2])
            tgt_team = int(parts[-3])
            pov_hash = parts[-4]
            csid = '_'.join(parts[:-4])
            record = {"timestamp":ts, "throws":throws, "path":pov, "hash":pov_hash}
            if csid in temp_povs:
                teams = temp_povs[csid]
                if tgt_team in teams:
                    newest = teams[tgt_team]
                    if ts > newest["timestamp"]:
                        src_path = os.path.join(pov_dir, newest["path"])
                        dst_path = os.path.join(install_path, newest["path"])
                        os.rename(src_path, dst_path)
                        teams[tgt_team] = record
                    else:
                        src_path = os.path.join(pov_file)
                        dst_path = os.path.join(install_path, os.path.basename(pov_file))
                        os.rename(src_path, dst_path)
                else:
                    temp_povs[csid][tgt_team] = record
            else:
                temp_povs[csid] = {tgt_team:record}

        #remember the newsest of each and move them
        self.installed_povs.update(temp_povs)
        for csid in temp_povs.items():
            for pov in csid[1].items():
                #TODO - could shell out to scp any submitted povs to thrower ??
                #subprocess.check_call(["scp", os.path.join(pov_dir, pov[1]["path"]), self.pov_thrower])
                src_path = os.path.join(pov_dir, pov[1]["path"])
                dest_name = os.path.join(install_path, pov[1]["path"])
                os.rename(src_path, dest_name)
                #update path to reflect new location
                pov[1]["path"] = dest_name

        self.issue_povs()

    def write_consensus_ids(self, eval_dir):
        for filters in self.installed_filters.items():
            #filters will be a tuple of (team, installed_filters)
            eval_path = os.path.join(eval_dir, str(filters[0]))
            status = {}

            ids_list = []
            installed = filters[1]
            for ids_filter in installed.items():
                filt = {}
                filt['csid'] = ids_filter[0]
                filt['hash'] = ids_filter[1]['hash']
                filt['uri'] = make_uri(ids_filter[1]['path'])
                ids_list.append(filt)

            status["ids"] = ids_list

            with open(eval_path, 'wb') as status_file:
                status_file.write(json.dumps(status, indent=True, sort_keys=True))

    def distribute_ids(self, eval_dir):
        install_path = os.path.join(self.web_root, "dl", str(self.my_team), "ids")
        try_makedirs(install_path)

        #TODO - shell out to scp any submitted filters to network appliance ??

        filter_dir = os.path.join(self.web_root, 'ids')

        try:
            (dirpath, _, new_filters) = os.walk(filter_dir).next()
        except StopIteration:
            logging.error("No IDS filters to distribute")
            new_filters = []

        #TODO: update map of currently installed filters
        #csid -> filtername (with hash suffix)

        temp_ids = {} #handle multiple submissions against same csid
        #now move to evaluation directory
        for ids_filter in new_filters:
            filter_file = os.path.join(dirpath, ids_filter)
            if is_locked(filter_file):
                #still being written by web server
                continue

            parts = ids_filter.split('_')
            ts = int(parts[-1][:-4])
            ids_hash = parts[-2]
            csid = '_'.join(parts[:-2])
            record = {"timestamp":ts, "path":ids_filter, "hash":ids_hash}
            if csid in temp_ids:
                newest = temp_ids[csid]
                if ts > newest["timestamp"]:
                    src_path = os.path.join(filter_dir, newest["path"])
                    dst_path = os.path.join(install_path, os.path.basename(newest["path"]))
                    os.rename(src_path, dst_path)
                    temp_ids[csid] = record
                else:
                    src_path = os.path.join(filter_file)
                    dst_path = os.path.join(install_path, os.path.basename(filter_file))
                    os.rename(src_path, dst_path)
            else:
                temp_ids[csid] = record

        self.my_filters.update(temp_ids)
        for ids_filter in temp_ids.items():
            #TODO - could shell out to scp any submitted filters from previous round to network appliance ??
            #subprocess.check_call(["scp", os.path.join(filter_dir, filter[1]["path"]), self.network_appliance])
            #all new filters in temp_ids are now available for consensus evaluation
            #but will not run until the next round
            filter_name = os.path.join(filter_dir, ids_filter[1]["path"])
            logging.debug("Installing %s as replacement ids filter", filter_name)

            src_path = os.path.join(filter_dir, ids_filter[1]["path"])
            dst_path = os.path.join(install_path, os.path.basename(src_path))
            os.rename(src_path, dst_path)

            #update path to reflect new location
            ids_filter[1]["path"] = os.path.join(install_path, ids_filter[1]["path"])

        self.issue_ids()
        self.write_consensus_ids(eval_dir)

    def write_consensus_rcb(self, eval_dir):
        for rcbs in self.installed_cbs.items():
            #filters will be a tuple of (team, installed_filters)
            eval_path = os.path.join(eval_dir, str(rcbs[0]))
            status = {}

            rcb_list = []
            installed = rcbs[1]
            for rcb in installed.items():
                rb = {}
                rb['cbid'] = rcb[0]
                rb['hash'] = rcb[1]['hash']
                rb['csid'] = rcb[1]['csid']
                rb['uri'] = make_uri(rcb[1]['path'])
                rcb_list.append(rb)

            status["cb"] = rcb_list

            with open(eval_path, "w") as status_file:
                status_file.write(json.dumps(status, indent=True, sort_keys=True))

    def cbinfo_from_name(self, path):
        parts = path.split('_')
        ts = int(parts[-1])
        rcb_hash = parts[-2]
        cbid = '_'.join(parts[:-2])

        csid = parts[0]
        parts_idx = 1
        while True:
            if csid in self.csets:
                break
            csid += "_" + parts[parts_idx]
            parts_idx += 1

        return (ts, cbid, csid, path, rcb_hash)

    def distribute_rcb(self, eval_dir):
        install_path = os.path.join(self.web_root, "dl", str(self.my_team), "cb")
        try_makedirs(install_path)
        # ADDED: copy rcbs to different folder for cb-test inspection
        fielded_path = os.path.join(self.web_root, 'rcb_fielded')
        try_makedirs(fielded_path)
        # /ADDED

        #TODO - shell out to scp any submitted rcbs to defended host ??
        rcb_dir = os.path.join(self.web_root, 'rcb')

        try:
            (dirpath, _, new_rcb) = os.walk(rcb_dir).next()
        except StopIteration:
            logging.error("No RCBs to distribute")
            new_rcb = []

        #TODO: update map of currently installed rcbs
        #cbid -> filename (with hash suffix)

        temp_rcb = {} #handle multiple submissions against same csid

        #now move to evaluation directory
        for rcb in new_rcb:
            rcb_file = os.path.join(dirpath, rcb)
            if is_locked(rcb_file):
                #still being written by web server
                continue

            ts, cbid, csid, path, rcb_hash = self.cbinfo_from_name(rcb)
            record = {"timestamp":ts, "csid":csid, "path":rcb, "hash":rcb_hash}
            if cbid in temp_rcb:
                newest = temp_rcb[cbid]
                if ts > newest["timestamp"]:
                    source = os.path.join(dirpath, newest['path'])
                    dest = os.path.join(install_path, os.path.basename(source))
                    os.rename(source, dest)
                    temp_rcb[cbid] = record
                else:
                    dest = os.path.join(install_path, os.path.basename(rcb_file))
                    os.rename(rcb_file, dest)
            else:
                temp_rcb[cbid] = record

        self.my_cbs.update(temp_rcb)
        for rcb in temp_rcb.items():
            #TODO - could shell out to scp any submitted rcbs from previous round to defended host ??
            #subprocess.check_call(["scp", os.path.join(rcb_dir, rcb[1]["path"]), self.def_host])
            #all new rcbs in temp_rcbs are now available for consensus evaluation
            #but will not run until the next round
            rcb_path = os.path.join(rcb_dir, rcb[1]["path"])
            logging.debug("Installing %s as replacement CB", rcb_path)
            src_path = rcb_path
            dst_path = os.path.join(install_path, os.path.basename(rcb_path))
            # ADDED: copy rcbs to different folder for cb-test inspection
            _, _, csid, _, _ = self.cbinfo_from_name(rcb[1]['path'])
            shutil.copyfile(src_path, os.path.join(fielded_path, csid))
            if (self.my_cbs_status[csid] in (self.NEW, self.NEW2)):
                self.my_cbs_status[csid] = self.SUBMITTED_WHEN_NEW
            else:
                self.my_cbs_status[csid] = self.DOWN
            # /ADDED
            os.rename(src_path, dst_path)
            #update path to reflect new location
            rcb[1]["path"] = os.path.join(install_path, rcb[1]["path"])

        # other teams RCBs
        self.issue_rcbs()
        self.write_consensus_rcb(eval_dir)

    def field_rcb(self):
        fielded_path = os.path.join(self.web_root, 'rcb_fielded')
        try_makedirs(fielded_path)
        (dirpath, _, cbnames) = os.walk(fielded_path).next()

        for csid in cbnames:
            rcb_path = os.path.join(dirpath, csid)
            if self.my_cbs_status[csid] == self.FIELDED:
                self.test_fielded_rcb(csid)

    def change_my_cbs_status(self):
        for csid in self.csets:
            if self.my_cbs_status[csid] == self.NEW:
                self.my_cbs_status[csid] = self.NEW2

            elif self.my_cbs_status[csid] == self.NEW2:
                self.my_cbs_status[csid] = self.FIELDED

            elif self.my_cbs_status[csid] == self.SUBMITTED_WHEN_NEW:
                self.my_cbs_status[csid] = self.DOWN

            elif self.my_cbs_status[csid] == self.DOWN:
                self.my_cbs_status[csid] = self.FIELDED

    def test_fielded_rcb(self, rcb):
        return
        #_, _, csid,  _, _ = self.cbinfo_from_name(rcb)
        #output_dir = os.path.join(self.web_root, "cbtests/round/%s" % self.round_num)
        #output_file = os.path.join(output_dir, csid)
        #cb_file = os.path.join(self.web_root, "rcb_fielded/%s" % rcb)
        #try_makedirs(output_dir)
        #cb_cmd = '/vagrant/bin/cbtest_wrapper.py -p %s -i %s %s > %s' % (self.polls, csid, cb_file, output_file)
        #logging.debug("CMD %s", cb_cmd)
	#global vm_to_test_on
	#vm_to_test_on = random.choice(ALL_VMS)
        #subprocess.Popen(['ssh', 'cb', '-x', cb_cmd])
        #logging.debug("Fielded CB %s", cb_file)

    def build_poll_summary_list(self):
        #fielded_path = os.path.join(self.web_root, 'rcb_fielded')
        #results_path = os.path.join(self.web_root, "cbtests/round/%s" % (self.round_num - 1))
        result = []
        for rcb in self.my_cbs.values():
            csid, cb_path = rcb['csid'], rcb['path']

            cb_hash = hash_file(cb_path)
            if cb_hash not in self.cached_scores:
                poll = {
                    'csid': csid,
                    'functionality': {
                        'success': '100',
                        'timeout': '0',
                        'connect': '0',
                        'function': '0'
                    },
                    'performance': {
                        'time': '100',
                        'memory': '100'
                    }
                }
                result.append(poll)
                continue

            success, timeout, connect, function, perf_time, perf_memory = self.cached_scores[cb_hash]

            #total = 100

            #success = random.randint(0, total - 30)
            #total -= success

            #timeout = random.randint(0, max(0, total - 20))
            #total -= timeout

            #connect = random.randint(0, max(0, total - 10))
            #total -= connect

            #function = total

            #assert 100 == success + timeout + connect + function

            #results = os.path.join(results_path, csid)
            #data = None
            #if os.path.isfile(results):
            #    with open(results) as jsonfile:
            #        try:
            #            data = json.load(jsonfile)
            #        except ValueError:
            #            pass
            #if data is not None:
            #    perf_time = int((data['tested']['scores']['ExecTimeOverhead'] + 1) * 100)
            #    perf_memory = int((data['tested']['scores']['MemUseOverhead'] + 1) * 100)
            #    logging.debug("Results %s: %s", results, perf)
            #else:
            #    perf_time = 'NOT AVAILABLE_YET'
            #    perf_memory = 'NOT AVAILABLE_YET'

            poll = {
                'csid': csid,
                'functionality': {
                    'success': success,
                    'timeout': timeout,
                    'connect': connect,
                    'function': function
                },
                'performance': {
                    'time': perf_time,
                    'memory': perf_memory
                }
            }
            print 'Provided this feedback:', poll
            result.append(poll)
        sys.stdout.flush()
        return result

    def write_poll_feedback(self, path):
        #generate poll summary
        poll = {}

        result_list = self.build_poll_summary_list()
        poll['poll'] = result_list

        with open(os.path.join(path, "poll"), "wb") as poll_file:
            poll_file.write(json.dumps(poll, indent=True, sort_keys=True))

    def build_pov_result_list(self):
        #TODO - implement me
        result = []
        for csid in self.installed_povs.items():
            for pov in csid[1].items():
                for throw in range(pov[1]["throws"]):
                    attempt = {}
                    attempt["csid"] = csid[0]
                    attempt["team"] = pov[0]
                    attempt["throw"] = throw + 1

                    #pick a random result
                    #TODO tie in to actual thrower result log??
                    if random.randint(0, 1) == 1:
                        attempt["result"] = "success"
                    else:
                        attempt["result"] = "fail"
                        fail_type = random.randint(0, 9)
                        #simulate 30% of failures as some sort of negotiate failure
                        if fail_type < 3:
                           attempt["error"] = negotiation_failures[fail_type]
                        else:
                           #this simulates a successful negotiation followed by a pov fail
                           #ie failed to cause a crash during a type 1 attempt, crashed with bad
                           #   register values, or submitted invalid type 2 result data
                           attempt["error"] = "unsuccessful"
                    result.append(attempt)
        return result

    def write_pov_feedback(self, path):
        #generate pov summary
        pov = {}

        result_list = self.build_pov_result_list()
        pov['pov'] = result_list

        with open(os.path.join(path, "pov"), "w") as pov_file:
            pov_file.write(json.dumps(pov, indent=True, sort_keys=True))

    def build_crash_list(self):
        #report small, random number of crashes
        crashes = random.randrange(10)
        crash_list = []

        for c in range(crashes):
            crash = {}

            #need to obtain a cbid here
            cset_id = random.choice(self.csets.items())
            crash["csid"] = cset_id[0]
            crash["cbid"] = cset_id[0]
            if cset_id[1] > 1:    # this is a multi cb set
                crash["cbid"] += "_%d" % random.randint(1, cset_id[1])

            #pick random timestamp in the last round
            rel_time = random.randrange(self.round_length + 1)
            crash["timestamp"] = self.round_time + rel_time

            #pick random signal number
            crash["signal"] = random.choice(self.signals)

            crash_list.append(crash)
        return crash_list

    def write_cb_feedback(self, path):
        #generate poll summary
        cb = {}
        cb["cb"] = self.build_crash_list()
        with open(os.path.join(path, "cb"), "w") as cb_file:
            cb_file.write(json.dumps(cb, indent=True, sort_keys=True))

    def update_scores(self):
        for t in self.scores:
            self.scores[t] += random.randrange(100)

    def write_status(self):
        status = {}
        status["round"] = self.round_num
        score_list = []
        place = len(self.scores)
        for score in sorted(self.scores.items(), key=lambda x: x[1]):
            team = {}
            team["team"] = score[0]
            team["score"] = score[1]
            team["rank"] = place
            score_list.append(team)
            place -= 1
        status["scores"] = score_list
        with open(os.path.join(self.web_root, "status"), "w") as status_file:
            status_file.write(json.dumps(status, indent=True, sort_keys=True))

    def run(self, rounds):
        while True:
            self.round_time = int(time.time())
            self.write_round_num()
            logging.debug("%s Starting round: %d", time.ctime(self.round_time), self.round_num)

            # install CBs and rotate CBs every cs_limit rounds
            if (self.round_num % self.cs_rounds_duration) == 0:
                self.rotate_cbs()
                self.install_cbs()
                self.install_filters()

            # ADDED: field rcbs
            self.field_rcb()

            #make sure this round's feedback and evaluation directories exist
            cb_path = os.path.join(self.web_root, "round", str(self.round_num), "evaluation", "cb")
            try_makedirs(cb_path)
            ids_path = os.path.join(self.web_root, "round", str(self.round_num), "evaluation", "ids")
            try_makedirs(ids_path)
            path = os.path.join(self.web_root, "round", str(self.round_num), "feedback")
            try_makedirs(path)

            #move stuff to download directories
            self.distribute_rcb(cb_path)
            self.distribute_ids(ids_path)
            self.distribute_pov()

            self.write_poll_feedback(path)
            self.write_pov_feedback(path)
            self.write_cb_feedback(path)

            if self.round_num > 0:
                self.update_scores()

            #update status file
            self.write_status()

            logging.debug("MY CBS STATUS %s", self.my_cbs_status)
            #sleep until end of round
            logging.debug("--------------------------------------------------------------------------------")
            time.sleep(self.round_length)

            # cbs state machine
            self.change_my_cbs_status()

            self.round_num += 1
            if rounds is not None and self.round_num >= rounds:
                logging.debug("Finished! good bye")
                break

def show_warning():
     warning = ("WARNING: Virtual Competition for finals in DARPA's Cyber Grand "
                    "Challenge, for use in verifying the API capability with the "
                    "competition framework. Data created by the virtual "
                    "competition is synthetic in nature and is only intended to be "
                    "used to test the API compatibility of competitor's CRSs.\n")
     print warning

def main():
    show_warning()

    formatter = argparse.ArgumentDefaultsHelpFormatter
    parser = argparse.ArgumentParser(description='Simulate rotation of CFE rounds',
                                                formatter_class=formatter)

    required = parser.add_argument_group(title='required')
    required.add_argument('--roundlen', required=False, type=int, default=300,
                                 help='Length of a round in seconds')

    parser.add_argument('--debug', required=False, action='store_true',
                              default=False, help='Enable debugging')

    parser.add_argument('--log', required=False, type=str, help='Log filename')

    parser.add_argument('--cbdir', required=True, type=str,
                              help='Initial CB directory')

    parser.add_argument('--webroot', required=True, type=str,
                              help='ti-server web root directory, attempts to create if it does not exist')

    parser.add_argument('--team', required=False, type=int, default=6, help='Simulate playing as the specified team (0-7)')
    parser.add_argument('--rounds', required=False, type=int, help='How many rounds to simulate')
    parser.add_argument('--polls', required=False, type=int, help='How many polls run for each binary')
    parser.add_argument('--cs-limit', required=False, type=int, default=30,
                              help='Number of CB sets available at once')
    parser.add_argument('--cs-rounds-duration', required=False, type=int, default=10,
                              help='Number of rounds before CB sets are changed')

    args = parser.parse_args()

    round_length = args.roundlen

    assert os.path.isdir(args.cbdir), "--cbdir is not a directory: %s. Virtual Competition requires CBs to be present." % args.cbdir


    if round_length < 0:
        logging.error("Round length must be a positive integer\n")
        sys.exit(1)

    if args.rounds is not None:
        assert args.rounds > 0

    logger = logging.getLogger()
    logger.setLevel(logging.WARNING)
    if args.debug:
        logger.setLevel(logging.DEBUG)

    if args.log is not None:
        log_fh = open(args.log, 'w')
    else:
        log_fh = sys.stdout

    log_handler = logging.StreamHandler(log_fh)
    log_handler.setFormatter(logging.Formatter('# %(message)s'))

    logger.addHandler(log_handler)

    if log_fh != sys.stdout:
        error_handler = logging.StreamHandler(sys.stdout)
        error_handler.setLevel(logging.ERROR)
        error_handler.setFormatter(logging.Formatter('# %(message)s'))
        logger.addHandler(error_handler)

    webroot_abs = os.path.abspath(args.webroot)

    rotator = Rotator(round_length, webroot_abs, args.cbdir, args.team, args.polls, args.cs_limit, args.cs_rounds_duration)
    try:
        rotator.run(args.rounds)
    except KeyboardInterrupt:
        logger.warning('interrupted')
    return 0

if __name__ == "__main__":
    exit(main())
